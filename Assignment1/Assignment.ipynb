{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bd568d-3568-4a08-914a-1d671e6055da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment1: Prototypical Networks\n",
    "\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/oscarknagg/few-shot/master/assets/proto_nets_diagram.png\"/></center>\n",
    "\n",
    "> Figure 1: Prototypical networks in a nutshell. In a 3-way 5-shot classification task, the class\n",
    "prototypes c1, c2, c3 are computed from each class’s support features (colored circles). The\n",
    "prototypes define decision boundaries based on Euclidean distance. A query example $x$\n",
    "is determined to be class 2 since its features (white circle) lie within that class’s decision\n",
    "region.\n",
    "\n",
    "\n",
    "In this assignment, let's use [**prototypical networks**](https://papers.nips.cc/paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html) to solve the *n-way k-shot few-shot learning* problem with the [Omniglot](https://www.tensorflow.org/datasets/catalog/omniglot) dataset. \n",
    "\n",
    "- **IMPORTANT**: 과제 제출하실 때 레포트를 pdf로 변환하고, `Assignment.ipynb`, `dataloader.py`, `model.py`, `train.py`, 모두 압축해서 **이름_학번_Assignment1.zip** 형식으로 ETL에 올리시길 바랍니다.\n",
    "- Assignment 1 is due 23:59 PM 4/14. Note that 10%p of your score will be deducted for every hour you are late.\n",
    "- Make sure you are using the latest version of [TensorFlow](https://www.tensorflow.org/api_docs/python/tf), or at least the 2.3 version.\n",
    "- *If you have any questions regarding the assignment, please contact me at steve2972@snu.ac.kr*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd832e9-f3f6-475f-9349-3caef2d1c554",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "We define a **task** to be an *n-way k-shot* image classification problem. The maximum number of tasks that can be created from a dataset can be defined as $M \\choose N$$\\cdot$$ K \\choose k$ where $M$=the number of classes in the dataset, $N$=the number of classes in a task, $K$=the total number of images in a class, and $k$=the number of shots in a class. In this problem, we define a method to create an upper bound to the number of tasks used during training. \n",
    "\n",
    "**Problem**: In the `dataloader.py` file, complete the implementation of the `DataLoader.generate_task_list` method and the `DataLoader.data_generator` method. Details concerning the implementation are as follows:\n",
    "\n",
    "- The `generate_task_list` method generates a **list of dictionaries** where each dictionary comprises a **task** in the form of `{class_name: [random sequence of image indexes]}`\n",
    "    - For example, a 2-way 5-shot task for both the support & query datasets can be generated as `{'A': [1,3,5,7,9,2,4,6,8, 10], 'B': [8,6,4,10,2,1,5,3,7,9]}`\n",
    "    - Note that the length of the random sequence of image indexes should equal the # of shots in the support dataset $+$ # of shots in the query dataset.\n",
    "    \n",
    "- The `data_generator` method generates a **support** and a **query dataset** where each dataset is in the form of a numpy array with shape `[num_way, num_shot, image_width, image_height, num_channels]`.\n",
    "    - Note that `data_generator` is created based on tasks which have the form `{class_name: [random sequence of image indexes]}`\n",
    "    \n",
    "If the `dataloader.py` file is implemented correctly, the following code should run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2382c2-8f38-4179-a7bb-1387c551bb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fembem\\anaconda3\\envs\\tf-2.8\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing train Omniglot dataset\n",
      "Finished preprocessing\n",
      "Preprocessing test Omniglot dataset\n",
      "Finished preprocessing\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataLoader\n",
    "\n",
    "num_ways = 5\n",
    "support_shots = 5\n",
    "query_shots = 5\n",
    "\n",
    "train_dataset = DataLoader('train', n_way=num_ways, n_support=support_shots, n_query=query_shots)\n",
    "val_dataset = DataLoader('test', n_way=num_ways, n_support=support_shots, n_query=query_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bff77-39a0-4950-8305-a964d802b361",
   "metadata": {},
   "source": [
    "**If implemented correctly, we can also visualize a random task using the `visualize_random_task` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e14ae5c-8949-4afb-90d7-99505264df52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_dataset.data.keys()\n",
    "# train_dataset.generate_task_list(n_tasks=1)\n",
    "# print(len(train_dataset.data.keys()))\n",
    "# print(list(train_dataset.data.items()))\n",
    "# train_dataset.task_list\n",
    "train_dataset.visualize_random_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3d864-c566-4f3f-b607-f10668d246df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "Next we will implement the prototypical network and examine how the performance of the model changes when **the total number of tasks is changed from 1k to 10k**.\n",
    "\n",
    "As discussed in the lecture, the basic idea of protonets is to learn a mapping $f_\\theta(\\cdot)$ from images to features such that images of the same class are close to each other in a feature space. Central to this is the notion of a *prototype*\n",
    "\n",
    "$$c_n = \\frac{1}{K} \\sum_{(x,y)\\in\\mathcal{D}^{tr}_i:y=n} f_\\theta(x)$$\n",
    "\n",
    "i.e. for task $i$, the prototype of the $n$-th class $c_n$ is defined as the mean of the $K$ feature\n",
    "vectors of that class’s support images. To classify some image $x$, we compute a measure of\n",
    "distance $d$ between $f_\\theta(x)$ and each of the prototypes. We will use the squared Euclidean\n",
    "distance:\n",
    "\n",
    "$$d(f_\\theta(x),c_n) = ||f_\\theta(x) - c_n ||^2_2$$\n",
    "\n",
    "We interpret the negative squared distances as **logits**, or *unnormalized log-probabilities,\n",
    "of* $x$ *belonging to each class*. To obtain the proper probabilities, we apply the softmax\n",
    "operation:\n",
    "\n",
    "$$p_\\theta(y = n|x) = \\frac{\\exp(-d(f_\\theta(x),c_n))}{\\sum^N_{n'=1}\\exp(-d(f_\\theta(x),c_{n'}))}$$\n",
    "\n",
    "Because the softmax operation preserves ordering, the class whose prototype is closest to\n",
    "$f_\\theta(x)$ is naturally interpreted as the most likely class for $x$. To train the model to generalize,\n",
    "we compute prototypes using support data, but minimize the negative log likelihood of the query data\n",
    "\n",
    "$$\\mathcal{J}(\\theta) = \\mathbb{E}_{\\mathcal{T}\\sim p(\\mathcal{T}), (\\mathcal{D}^{tr}, \\mathcal{D}^{ts})\\sim \\mathcal{T}} \\left[ \\frac{1}{NQ} \\sum_{(x^{ts},y^{ts})\\sim\\mathcal{D}^{ts}} -\\log p_\\theta(y=y^{ts} | x^{ts})\\right]$$\n",
    "\n",
    "Notice that this is equivalent to using a cross-entropy loss.\n",
    "\n",
    "We optimize $\\theta$ using Adam, and as is standard for stochastic gradient methods, we approximate the objective for $\\mathcal{J}$ with\n",
    "Monte Carlo estimation on minibatches of tasks. Thus, for one minibatch of size $B$, we have\n",
    "\n",
    "$$\\mathcal{J}(\\theta) \\approx \\frac{1}{B}\\sum_{i=1}^B \\left[ \\frac{1}{NQ} \\sum_{(x^{ts},y^{ts})\\sim\\mathcal{D}^{ts}} -\\log p_\\theta(y=y^{ts} | x^{ts})\\right]$$\n",
    "\n",
    "\n",
    "**Problem:**\n",
    "\n",
    "1. In the `model.py` file, complete the implementation of the `Prototypical_Network.call` method. Pay attention to the inline comments.\n",
    "2. Test the model with different amounts of training tasks (e.g. from 1k to 10k).\n",
    "    1.  Create a plot of the validation accuracy using `matplotlib` and report your findings. \n",
    "        - Train and validate the model on 5-way 5-shot tasks for both the support and query datasets.\n",
    "        - [Hint]: you should obtain a query accuracy on the validation split of **at least** 97% with 10k tasks.\n",
    "    2. Also plot how the degree of overfitting (the difference between training accuracy and validation accuracy) changes with different amounts of tasks.\n",
    "3. Repeat (2) with different tasks [5way-1shot, 20way-5shot, 20way-1shot] and report your findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf817cd-de2e-463c-9016-64cee359d2b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "num_tasks = 10000 # The total number of tasks in the predefined task distribution\n",
    "num_epochs = 100 # The number of epochs to train the model\n",
    "num_tasks_per_epoch = 100 # The number of tasks to be trained on for each epoch\n",
    "\n",
    "# metrics = [train accuracies, train losses, validation accuracies, validation losses]\n",
    "metrics = train.train_model(train_dataset, val_dataset, \n",
    "                            n_tasks=num_tasks, n_epochs=num_epochs, \n",
    "                            n_tpe=num_tasks_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a6395-a092-440c-92be-d0bf79a0db74",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Finally, we will evaluate the generalization performance of the model by using a **different test setting from a training setting**.\n",
    "\n",
    "<br>\n",
    "\n",
    "As prototypical networks are based on a nonparametric method, we can flexibly train the model with different types of tasks (e.g. 5way1shot tasks + 5way5shot tasks). Let's assume we are allowed to use up to 30 training samples to train a single task. Evaluate the performance of the model when we train the model using **randomly defined training tasks**.\n",
    "\n",
    "\n",
    "\n",
    "**Problem**:\n",
    "\n",
    "1. In the `dataloader.py` file, implement the `random_data_generator` method.\n",
    "2. Using the experimental details outlined below, run experiments and compare with the results from Problem 2\n",
    "    - Note that you do not need to specify a set number of tasks for this problem\n",
    "\n",
    "\n",
    "**Experimental Details**:\n",
    "- *Train setting*: Assume to use exactly 30 images for each task (for support + query). First randomly select $N$ from the set $\\{2, 3, 5, 6, 10, 15\\}$. This means that each $N$ can use $\\{15, 10, 6, 5, 3, 2\\}$ samples per class respectively. By properly splitting the number of samples into 2 splits (support/query), we can randomly define different tasks.\n",
    "    - For example, an example support/query task can be defined as support={5-way 4-shot}, and query={5-way 2-shot}.\n",
    "    - *Extra Credit (optional)*: implement and test a method where we use a flexible number of images (not limited to just 30) where $N$ can also be defined randomly.\n",
    "- *Test setting*: 5way 5 shot (5$\\cdot$5 for support + 5$\\cdot$1 for query = 30 images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b81f55-0b23-41b0-9a2c-44164eb58f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ways = 5\n",
    "support_shots = 5\n",
    "query_shots = 1\n",
    "\n",
    "train_dataset = DataLoader('train')\n",
    "val_dataset = DataLoader('test', n_way=num_ways, n_support=support_shots, n_query=query_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d925446-05fd-4ea0-9422-aab4c82e0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 # The number of epochs to train the model\n",
    "num_tasks_per_epoch = 100 # The number of tasks to be trained on for each epoch\n",
    "\n",
    "# metrics = [train accuracies, train losses, validation accuracies, validation losses]\n",
    "metrics = train.train_model(train_dataset, val_dataset, \n",
    "                            n_tasks=num_tasks, n_epochs=num_epochs, \n",
    "                            n_tpe=num_tasks_per_epoch, is_random=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
